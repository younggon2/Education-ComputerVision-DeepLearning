{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to access this in Colab\n",
    "본 실습에서는 모델 학습 단에서 DICOM원본을 받기에는 용량에 한계가 있어, PNG파일을 활용합니다.\n",
    "1. 개인 google drive에 폴더를 생성해주세요.\n",
    "2. 이 ipynb 파일과 아래 링크에서 data, dense_ckpt01 폴더를 받아서 같은 디렉토리에 저장해주세요.  \n",
    "https://drive.google.com/drive/folders/19QLnvMjG4iAbvxq7s3xjYD43keN6kHzK?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ttach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSNA Intracranial Hemorrhage Detection\n",
    "In this competition, your challenge is to build an algorithm to detect acute intracranial hemorrhage and its subtypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intracranial hemorrhage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![subtype](./sample/subtypes-of-hemorrhage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 실습에서는 kaggle의 'RSNA Intracranial Hemorrhage Detection' challenge의 `Brain CT 데이터셋`을 활용하여  \n",
    "`CT의 각 slice를 Intracranial Hemorrhage의 총 5가지 subtype으로 분류하는 classification model` 구축을 진행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to access this dataset?\n",
    "본 실습에서는 모델 학습 단에서 DICOM원본을 받기에는 용량에 한계가 있어, PNG파일을 활용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "FILE_EXTENSION = ['.img', '.IMG', '.jpg', '.JPG', '.jpeg', '.JPEG', '.png', \\\n",
    "                  '.PNG', '.gif', '.GIF', 'dcm', 'DCM', '.csv', '.CSV']\n",
    "DCM_EXTENSION = ['.dcm', '.DCM']\n",
    "IMG_EXTENSION = ['.img', '.IMG', '.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.gif', '.GIF']\n",
    "PNG_EXTENSION = ['.png', '.PNG']\n",
    "\n",
    "def check_extension(filename, extension_ls=FILE_EXTENSION):\n",
    "    # filename이 해당 확장자(extension_ls)로 되어있는 경우 True\n",
    "    return any(filename.endswith(extension) for extension in extension_ls)\n",
    "\n",
    "def load_file_paths(folder_path, extension_ls=FILE_EXTENSION):\n",
    "    \"\"\"\n",
    "    find 'extension_ls' file paths in folder.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str) -- folder directory\n",
    "        extension_ls (list) -- list of extensions\n",
    "    \n",
    "    Return:\n",
    "        file_paths (list) -- list of 'extension_ls' file paths\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    file_paths = []\n",
    "    assert os.path.isdir(folder_path), f'{folder_path} is not a valid directory'\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(folder_path)):\n",
    "        for fname in fnames:\n",
    "            if check_extension(fname, extension_ls):\n",
    "                path = os.path.join(root, fname)\n",
    "                file_paths.append(path)\n",
    " \n",
    "    return file_paths[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def set_outside_scanner_to_air(hu_pixelarrays):\n",
    "    \"\"\"\n",
    "    Pixel Padding Value Attribute(0028,0120) -> air\n",
    "    \"\"\"\n",
    "    hu_pixelarrays[hu_pixelarrays < -1024] = -1024\n",
    "    \n",
    "    return hu_pixelarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def transform_to_hu(dicom_info, image):\n",
    "    image = set_outside_scanner_to_air(image)\n",
    "    \n",
    "    intercept = dicom_info.RescaleIntercept\n",
    "    slope = dicom_info.RescaleSlope\n",
    "    hu_image = image.astype(np.float64) * slope + intercept\n",
    "    hu_image = set_outside_scanner_to_air(hu_image.astype(np.int16))\n",
    "    return hu_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def ct_img_loader(dcm_path):\n",
    "    \"\"\"\n",
    "    Function of Loading CT-scan\n",
    "    patient path to CT slices(HU)\n",
    "    \n",
    "    Parameters:\n",
    "        dcm_path (str) -- dicom file path\n",
    "    \n",
    "    Return:\n",
    "        dcm_img (np.array) -- CT slice(HU)\n",
    "    \"\"\"\n",
    "    # force=True : reading even if no File Meta Information header is found\n",
    "    dcm_info = pydicom.read_file(dcm_path, force=True)\n",
    "    tmp_img = dcm_info.pixel_array\n",
    "    dcm_img = transform_to_hu(dcm_info, tmp_img)\n",
    "    \n",
    "    return dcm_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class CT_Windowing:\n",
    "    \"\"\"\n",
    "    CT image windowing : WL_Window Level, WW_Window Width\n",
    "    \"\"\"\n",
    "   \n",
    "    def __init__(self, mode='custom', custom_window=None, norm=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            mode (str)(WL|WW) -- \n",
    "                'abdomen'(60|400) , 'bone'(300|1500), 'brain'(40|80), \n",
    "                'chest'(40|400), 'lung'(-700|1500), 'custom'(WL|WW)\n",
    "            custom_window (list or tuple) -- \n",
    "                if mode == 'custom', set custom_window(WL, WW)\n",
    "            norm (bool) -- normalize to uint8 (0~255)\n",
    "\n",
    "        \"\"\"\n",
    "        option = ['abdomen' , 'bone', 'brain', 'chest', 'lung', 'subdural', 'custom']\n",
    "        assert mode in option, \"Wrong mode: Enter \\'abdomen\\' , \\'bone\\', \\\n",
    "                                \\'brain\\', \\'chest\\', \\'lung\\', \\'subdural\\', \\'custom\\'\"\n",
    "        \n",
    "        self.mode = \"window_\" + mode\n",
    "        if custom_window is not None:\n",
    "            self.w_level = custom_window[0]\n",
    "            self.w_width = custom_window[1]\n",
    "            \n",
    "        self.norm = norm\n",
    "        \n",
    "    def windowing(self):\n",
    "        self.w_min = self.w_level - (self.w_width / 2)\n",
    "        self.w_max = self.w_level + (self.w_width / 2)\n",
    "        window_image = self.img.copy()\n",
    "        window_image[window_image < self.w_min] = self.w_min\n",
    "        window_image[window_image > self.w_max] = self.w_max\n",
    "        \n",
    "        if self.norm:\n",
    "            window_image = np.uint8(((window_image - self.w_min) / \\\n",
    "                                     (self.w_max - self.w_min)) * 255.0)\n",
    "        return window_image\n",
    "        \n",
    "    def window_abdomen(self):\n",
    "        self.w_level = 60\n",
    "        self.w_width = 400\n",
    "        \n",
    "        return self.windowing()\n",
    "        \n",
    "    def window_bone(self):\n",
    "        self.w_level = 300\n",
    "        self.w_width = 1500\n",
    "        \n",
    "        return self.windowing()\n",
    "    \n",
    "    def window_brain(self):\n",
    "        self.w_level = 40\n",
    "        self.w_width = 80\n",
    "        \n",
    "        return self.windowing()\n",
    "    \n",
    "    def window_chest(self):\n",
    "        self.w_level = 40\n",
    "        self.w_width = 400\n",
    "        \n",
    "        return self.windowing()\n",
    "        \n",
    "    def window_lung(self):\n",
    "        #SNUH version\n",
    "        self.w_level = -700\n",
    "        self.w_width = 1500\n",
    "        \n",
    "        return self.windowing()\n",
    "    \n",
    "    def window_subdural(self):\n",
    "        # RSNA Intrracranial Hemorrhage : See like a Radiologist with Systematic Windowing\n",
    "        # https://www.kaggle.com/dcstang/see-like-a-radiologist-with-systematic-windowing\n",
    "        self.w_level = 80\n",
    "        self.w_width = 200\n",
    "        \n",
    "        return self.windowing()\n",
    "        \n",
    "    def window_custom(self):\n",
    "        return self.windowing()\n",
    "    \n",
    "    def __call__(self, hu_img):\n",
    "        self.img = hu_img\n",
    "        self.opt = getattr(self, self.mode, lambda:'custom')\n",
    "        return self.opt()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hemo_image'></a> \n",
    "## Data pipeline: working with DICOM files and csv files\n",
    "학습을 위한 데이터셋을 만들기 위해 label(.csv)과 data(.dcm)을 매칭해줍니다.  \n",
    "실습의 편의를 위해 DICOM파일은 CT를 brain window setting에 맞게 windowing한 PNG 이미지 파일로 대체하였습니다.  \n",
    "실습에서 다루는 데이터는 2000장의 CT slices로 원본 데이터보다 매우 적습니다.  \n",
    "원본데이터 다운로드는 아래의 링크를 참고하세요.  \n",
    "https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본 데이터를 사용할 경우 TRAIN_PATH = \"./data/rsna-intracranial-hemorrhage-detection/stage_2_train\"\n",
    "TRAIN_PATH = \"./data/rsna-intracranial-hemorrhage-detection/data_png\"\n",
    "\n",
    "#DCM file path 추출\n",
    "train_img_paths = load_file_paths(TRAIN_PATH, PNG_EXTENSION) #DCM_EXTENSION\n",
    "#label DataFrame\n",
    "new_train_label_df = pd.read_csv(\"./data/rsna-intracranial-hemorrhage-detection/new_train_label.csv\")\n",
    "new_train_label_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path에서 파일명만 추출\n",
    "train_img_id = [os.path.splitext(os.path.basename(p))[0] for p in train_img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame에서 DCM file이 있는 id만 추출\n",
    "sampled_train_df = new_train_label_df[new_train_label_df[\"id\"].isin(train_img_id)].reset_index(drop=True)\n",
    "sampled_train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label 과 dcm path 매치\n",
    "sampled_train_df['dcm_path'] = TRAIN_PATH + '/' + sampled_train_df['id'].values + '.png' #\".dcm\"\n",
    "sampled_train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split ~ train | validation | test\n",
    "편의를 위해 dataset을 random sampling하였습니다.  \n",
    "추후 연구를 위해서 case별로 sampling하는 것을 강권합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split (train | validation | test) ~ Randomsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상군과 비정상군의 데이터 비율을 확인\n",
    "normal_train_df = sampled_train_df[sampled_train_df[\"any\"]==0].reset_index(drop=True)\n",
    "abnormal_train_df = sampled_train_df[sampled_train_df[\"any\"]==1].reset_index(drop=True)\n",
    "print(\"정상군 데이터 개수: {}, 비정상군 데이터 개수: {}\".format(len(normal_train_df), len(abnormal_train_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습의 편의를 위해 정상군 데이터는 107933개만 사용\n",
    "np.random.seed(50)\n",
    "part_normal_train_df=normal_train_df.iloc[np.random.permutation(normal_train_df.index)].reset_index(drop=True).iloc[:107933]\n",
    "part_sample_train_df=pd.concat([part_normal_train_df,abnormal_train_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 subtype과 dcm_path를 np.array로 추출\n",
    "CLASS_NAME = [\"epidural\", \"intraparenchymal\", \"intraventricular\", \"subarachnoid\", \"subdural\"]\n",
    "dataset_arr = part_sample_train_df[[\"dcm_path\"]+CLASS_NAME].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset -> [train, val, internal test] (2:1:1)\n",
    "seed = 37\n",
    "part_x_dataset = dataset_arr[:,0]\n",
    "part_y_dataset = dataset_arr[:,1:]\n",
    "#stratify_label = sampled_train_df[\"any\"].values\n",
    "\n",
    "# train : val+test = 6:4\n",
    "# stratify를 사용하면 label의 비율을 유지할 수 있습니다.\n",
    "# 정상군과 비정상군의 label 비율을 유지하도록 하였습니다.\n",
    "x_tr, x_val_tst, y_tr, y_val_tst = train_test_split(part_x_dataset, part_y_dataset, test_size=0.5, shuffle=True, random_state=seed)#stratify=part_y_dataset\n",
    "# val : test = 1:1\n",
    "x_val, x_tst, y_val, y_tst = train_test_split(x_val_tst, y_val_tst, test_size=0.5, shuffle=True, random_state=seed) #stratify=y_val_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tr = np.hstack([x_tr[:,np.newaxis], y_tr])\n",
    "dataset_val = np.hstack([x_val[:,np.newaxis], y_val])\n",
    "dataset_tst = np.hstack([x_tst[:,np.newaxis], y_tst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train dataset total: \\t\\t{} \\n \\\n",
    "ratio of epidural : \\t\\t{} \\n \\\n",
    "ratio of intraparenchymal : \\t{} \\n \\\n",
    "ratio of intraventricular : \\t{} \\n \\\n",
    "ratio of subarachnoid : \\t{} \\n \\\n",
    "ratio of subdural : \\t\\t{}\"\n",
    ".format(len(dataset_tr), np.sum(dataset_tr[:, 1])/len(dataset_tr), \n",
    "              np.sum(dataset_tr[:, 2])/len(dataset_tr), \n",
    "              np.sum(dataset_tr[:, 3])/len(dataset_tr), \n",
    "              np.sum(dataset_tr[:, 4])/len(dataset_tr), \n",
    "              np.sum(dataset_tr[:, 5])/len(dataset_tr)))\n",
    "print(\"val dataset total: \\t\\t{} \\n \\\n",
    "ratio of epidural : \\t\\t{} \\n \\\n",
    "ratio of intraparenchymal : \\t{} \\n \\\n",
    "ratio of intraventricular : \\t{} \\n \\\n",
    "ratio of subarachnoid : \\t{} \\n \\\n",
    "ratio of subdural : \\t\\t{}\"\n",
    ".format(len(dataset_val), np.sum(dataset_val[:, 1])/len(dataset_val), \n",
    "              np.sum(dataset_val[:, 2])/len(dataset_val), \n",
    "              np.sum(dataset_val[:, 3])/len(dataset_val), \n",
    "              np.sum(dataset_val[:, 4])/len(dataset_val), \n",
    "              np.sum(dataset_val[:, 5])/len(dataset_val)))\n",
    "print(\"test dataset total: \\t\\t{} \\n \\\n",
    "ratio of epidural : \\t\\t{} \\n \\\n",
    "ratio of intraparenchymal : \\t{} \\n \\\n",
    "ratio of intraventricular : \\t{} \\n \\\n",
    "ratio of subarachnoid : \\t{} \\n \\\n",
    "ratio of subdural : \\t\\t{}\"\n",
    ".format(len(dataset_tst), np.sum(dataset_tst[:, 1])/len(dataset_tst), \n",
    "              np.sum(dataset_tst[:, 2])/len(dataset_tst), \n",
    "              np.sum(dataset_tst[:, 3])/len(dataset_tst), \n",
    "              np.sum(dataset_tst[:, 4])/len(dataset_tst), \n",
    "              np.sum(dataset_tst[:, 5])/len(dataset_tst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_loader(img_path):\n",
    "    return np.array(Image.open(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = img_loader(dataset_tr[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(sample, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.title(dataset_tr[1][0].split('/')[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataset\n",
    "pytorch CustomDataset을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dataset에 대해 brain window로 preprocess를 진행하였습니다. (원본DCM을 이용할 경우 참고하세요)\n",
    "brain_window_fn = CT_Windowing(mode='brain', norm=True)\n",
    "def preprocess_fn(hu_image):\n",
    "    return brain_window_fn(hu_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNAHemoDataset(data.Dataset):\n",
    "    \"\"\" data_dir => np.array[[x_dir, y_label]] -> [str, list] \"\"\"\n",
    "    def __init__(self, \n",
    "                 data_dir, \n",
    "                 default_loader = None, #\n",
    "                 preprocess = None):    #preprocess_fn\n",
    "        \n",
    "        self.x_dir = data_dir[:,0]\n",
    "        self.y_label = data_dir[:,1:]\n",
    "        self.loader = default_loader\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.x_dir[index]\n",
    "        img = self.loader(path)\n",
    "        if self.preprocess is not None:\n",
    "            img = self.preprocess(img)\n",
    "        self.transform = get_transform()\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = np.array(self.y_label[index]).astype(float)\n",
    "        \n",
    "        sample = img, torch.FloatTensor(label)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(params=None, method=Image.BICUBIC, resize=[512, 512], convert=True):\n",
    "    transform_list = []\n",
    "    transform_list.append(transforms.ToPILImage())\n",
    "    #원하는 augmentation method를 추가하면 됩니다.\n",
    "    #transform_list.append(transforms.RandomAffine((-10, 10)))\n",
    "    \n",
    "    if resize:\n",
    "        transform_list.append(transforms.Resize(resize, method))  \n",
    "        \n",
    "    if convert:\n",
    "        transform_list += [transforms.ToTensor()]\n",
    "        transform_list += [transforms.Normalize((0.5), (0.5))]\n",
    "        \n",
    "    return transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RSNAHemoDataset(dataset_tr, \n",
    "                                default_loader = img_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16,\n",
    "                                          shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "data1 = dataiter.next()\n",
    "features, labels = data1\n",
    "#print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize를 역산하는 function\n",
    "def inverse_normalization(img, mean_std, grayscale=False):\n",
    "    tmp = []\n",
    "    if grayscale:\n",
    "        return img*mean_std[1][0] + mean_std[0][0]\n",
    "        \n",
    "    for l in range(3):\n",
    "        tmp.append((img[:,:,l]*mean_std[1][l]) + mean_std[0][l])\n",
    "        \n",
    "    return np.stack(tmp, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_norm_feature = inverse_normalization(features[1].permute(1, 2, 0),[(0.5,), (0.5,)], grayscale=True)\n",
    "plt.imshow(inv_norm_feature, cmap='gray')\n",
    "plt.grid(False)\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build classification model: multi-label classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multilabel](./sample/multiclass_vs_multilabel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 task는 multi-label classification이므로 마지막단에 activation으로 Sigmoid가 채택됩니다.  \n",
    "본 실습에서는 모델로 DenseNet161을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./sample/sigmoid.png\" height=\"200px\" width=\"600px\"> <img src=\"./sample/softmax.jpg\" height=\"200px\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: \n",
    "https://learnopencv.com/multi-label-image-classification-with-pytorch-image-tagging/  \n",
    "https://towardsdatascience.com/softmax-activation-function-explained-a7e1bc3ad60  \n",
    "https://medium.com/@toprak.mhmt/activation-functions-for-deep-learning-13d8b9b20e  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet\n",
    "import torchvision.models as models\n",
    "densenet161 = models.densenet161()\n",
    "densenet161.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "densenet161.classifier = nn.Sequential(nn.Linear(densenet161.classifier.in_features, len(CLASS_NAME)), \n",
    "                                       nn.Sigmoid()\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet161"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    Copied from: https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, epoch, n_epochs, print_freq=1000):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    error = AverageMeter()\n",
    "    \n",
    "    criterion = torch.nn.BCELoss().cuda() # Loss - Binary Cross-Entropy Loss(BCE Loss)\n",
    "    # Model on train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for batch_idx, (input, target) in enumerate(loader):\n",
    "        # Create vaiables\n",
    "        if torch.cuda.is_available():\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        batch_size = target.size(0)\n",
    "        pred = np.round(output.data.cpu().detach())\n",
    "        error.update(torch.ne(pred, target.cpu()).float().sum().item() / (target.size(1)*batch_size), batch_size)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        # compute gradient and do optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # print stats\n",
    "        if batch_idx % print_freq == 0:\n",
    "            res = '\\t'.join([\n",
    "                'Epoch: [%d/%d]' % (epoch + 1, n_epochs),\n",
    "                'Iter: [%d/%d]' % (batch_idx + 1, len(loader)),\n",
    "                'Time %.3f (%.3f)' % (batch_time.val, batch_time.avg),\n",
    "                'Loss %.4f (%.4f)' % (losses.val, losses.avg),\n",
    "                'Error %.4f (%.4f)' % (error.val, error.avg),\n",
    "            ])\n",
    "            print(res)\n",
    "\n",
    "    # Return summary statistics\n",
    "    return batch_time.avg, losses.avg, error.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, loader, print_freq=10, is_test=True):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    error = AverageMeter()\n",
    "    \n",
    "    criterion = torch.nn.BCELoss().cuda()\n",
    "    # Model on eval mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input, target) in enumerate(loader):\n",
    "            # Create vaiables\n",
    "            if torch.cuda.is_available():\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            batch_size = target.size(0)\n",
    "            pred = np.round(output.data.cpu().detach())\n",
    "            error.update(torch.ne(pred,target.cpu()).float().sum().item() / (target.size(1)*batch_size), batch_size)\n",
    "            losses.update(loss.item(), batch_size)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            # print stats\n",
    "            if batch_idx % print_freq == 0:\n",
    "                res = '\\t'.join([\n",
    "                    'Test' if is_test else 'Valid',\n",
    "                    'Iter: [%d/%d]' % (batch_idx + 1, len(loader)),\n",
    "                    'Time %.3f (%.3f)' % (batch_time.val, batch_time.avg),\n",
    "                    'Loss %.4f (%.4f)' % (losses.val, losses.avg),\n",
    "                    'Error %.4f (%.4f)' % (error.val, error.avg),\n",
    "                ])\n",
    "                print(res)\n",
    "\n",
    "    # Return summary statistics\n",
    "    return batch_time.avg, losses.avg, error.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_set, valid_set, test_set, save, n_epochs=300,\n",
    "          batch_size=64, lr=0.001, save_epoch=10, seed=None):\n",
    "    cnt=0\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True,\n",
    "                                               pin_memory=(torch.cuda.is_available()), num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False,\n",
    "                                              pin_memory=(torch.cuda.is_available()), num_workers=0)\n",
    "    if valid_set is None:\n",
    "        valid_loader = None\n",
    "    else:\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False,\n",
    "                                                   pin_memory=(torch.cuda.is_available()), num_workers=0)\n",
    "    # Model on cuda\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Wrap model for multi-GPUs, if necessary\n",
    "    model_wrapper = model\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model_wrapper = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model_wrapper.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[0.5 * n_epochs, 0.75 * n_epochs],\n",
    "                                                     gamma=0.1)\n",
    "\n",
    "    # Start log\n",
    "    with open(os.path.join(save, 'results.csv'), 'w') as f:\n",
    "        f.write('epoch,train_loss,train_error,valid_loss,valid_error,test_error\\n')\n",
    "\n",
    "    # Train model\n",
    "    best_error = 1\n",
    "    for epoch in range(n_epochs):\n",
    "        _, train_loss, train_error = train_epoch(\n",
    "            model=model_wrapper,\n",
    "            loader=train_loader,\n",
    "            optimizer=optimizer,\n",
    "            epoch=epoch,\n",
    "            n_epochs=n_epochs,\n",
    "        )\n",
    "        scheduler.step()\n",
    "        _, valid_loss, valid_error = test_epoch(\n",
    "            model=model_wrapper,\n",
    "            loader=valid_loader if valid_loader else test_loader,\n",
    "            is_test=(not valid_loader)\n",
    "        )\n",
    "\n",
    "        # Determine if model is the best\n",
    "        if valid_loader:\n",
    "            if valid_error < best_error:\n",
    "                best_error = valid_error\n",
    "                print('New best error: %.4f' % best_error)\n",
    "                torch.save(model.state_dict(), os.path.join(save, 'model_epoch'+str(cnt).zfill(3)+'.dat'))\n",
    "        else:\n",
    "            if (cnt%save_epoch==0):\n",
    "                torch.save(model.state_dict(), os.path.join(save, 'model_epoch'+str(cnt).zfill(3)+'.dat'))\n",
    "\n",
    "        # Log results\n",
    "        with open(os.path.join(save, 'results.csv'), 'a') as f:\n",
    "            f.write('%03d,%0.6f,%0.6f,%0.5f,%0.5f,\\n' % (\n",
    "                (epoch + 1),\n",
    "                train_loss,\n",
    "                train_error,\n",
    "                valid_loss,\n",
    "                valid_error,\n",
    "            ))\n",
    "        cnt+=1\n",
    "    torch.save(model.state_dict(), os.path.join(save, 'model_final.dat'))\n",
    "\n",
    "    # Final test of model on test set\n",
    "    model.load_state_dict(torch.load(os.path.join(save, 'model_final.dat')))\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "    test_results = test_epoch(\n",
    "        model=model,\n",
    "        loader=test_loader,\n",
    "        is_test=True\n",
    "    )\n",
    "    _, _, test_error = test_results\n",
    "    with open(os.path.join(save, 'results.csv'), 'a') as f:\n",
    "        f.write(',,,,,%0.5f\\n' % (test_error))\n",
    "    print('Final test error: %.4f' % test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './dense_ckpt01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(save, model,\n",
    "         n_epochs=300, batch_size=64, seed=None):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # Datasets\n",
    "    train_dataset = RSNAHemoDataset(dataset_tr, \n",
    "                                    default_loader = img_loader)\n",
    "    val_dataset = RSNAHemoDataset(dataset_val, \n",
    "                                  default_loader = img_loader)\n",
    "    test_dataset = RSNAHemoDataset(dataset_tst, \n",
    "                                   default_loader = img_loader)\n",
    "\n",
    "    # Models\n",
    "    #print(model)\n",
    "    \n",
    "    # Print number of parameters\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print(\"Total parameters: \", num_params)\n",
    "\n",
    "    # Make save directory\n",
    "    if not os.path.exists(save):\n",
    "        os.makedirs(save)\n",
    "    if not os.path.isdir(save):\n",
    "        raise Exception('%s is not a dir' % save)\n",
    "\n",
    "    # Train the model\n",
    "    train(model=model, train_set=train_dataset, valid_set=val_dataset, test_set=test_dataset, save=save,\n",
    "          n_epochs=n_epochs, batch_size=batch_size, seed=seed)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo(save_path, densenet161, n_epochs=100, batch_size=8, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = pd.read_csv('./dense_ckpt01/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('loss')\n",
    "plt.plot(np.array(train_history['train_loss']), 'b')\n",
    "plt.plot(np.array(train_history['valid_loss']), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('acc')\n",
    "plt.plot(1-np.array(train_history['train_error']), 'b')\n",
    "plt.plot(1-np.array(train_history['valid_error']), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './dense_ckpt01/'\n",
    "net_pre = models.densenet161()\n",
    "net_pre.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "net_pre.classifier = nn.Sequential(nn.Linear(net_pre.classifier.in_features, 5), nn.Sigmoid())\n",
    "\n",
    "net_pre.load_state_dict(torch.load(os.path.join(save_path, 'best_epoch.dat')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming score는 각각의 class에 대해 precision(TP/TP+FP)을 구하고 평균을 구합니다.\n",
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    '''\n",
    "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
    "    https://stackoverflow.com/q/32239577/395857\n",
    "    '''\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        #print('\\nset_true: {0}'.format(set_true))\n",
    "        #print('set_pred: {0}'.format(set_pred))\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        #print('tmp_a: {0}'.format(tmp_a))\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(testloader, model, class_num):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    output_arr = np.ones((1, class_num))\n",
    "    label_arr = np.ones((1, class_num))\n",
    "    pred_arr = np.ones((1, class_num))\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "   \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            images, labels = data\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "            predicted = torch.round(outputs.data)\n",
    "            \n",
    "            output_arr = np.concatenate((output_arr, outputs.cpu().numpy()), axis=0)\n",
    "            label_arr = np.concatenate((label_arr, labels.cpu().numpy()), axis=0)\n",
    "            pred_arr = np.concatenate((pred_arr, predicted.cpu().numpy()), axis=0)\n",
    "\n",
    "    output_arr = np.delete(output_arr, 0, axis=0)\n",
    "    label_arr = np.delete(label_arr, 0, axis=0)\n",
    "    pred_arr = np.delete(pred_arr, 0, axis=0)\n",
    "    # multi-label classification은 평가지표가 multi-class classification과는 다르고 다양합니다.\n",
    "    h_score = hamming_score(label_arr,pred_arr)\n",
    "    print('Hamming score on the test images: ', h_score)\n",
    "    \n",
    "    return h_score, output_arr, label_arr, pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = RSNAHemoDataset(dataset_tst,\n",
    "                               default_loader = img_loader)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False,\n",
    "                                          pin_memory=(torch.cuda.is_available()), num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_score, output_arr, label_arr, pred_arr = test_acc(test_loader, net_pre, class_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME = [\"epidural\", \"intraparenchymal\", \"intraventricular\", \"subarachnoid\", \"subdural\"]\n",
    "print(metrics.classification_report(label_arr, pred_arr, target_names=CLASS_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix : one vs rest\n",
    "cm = multilabel_confusion_matrix(label_arr, pred_arr)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one vs. rest\n",
    "cm = multilabel_confusion_matrix(label_arr, pred_arr)\n",
    "for idx, cm_i in enumerate(cm):\n",
    "    clss = ['rest', CLASS_NAME[idx]]\n",
    "    df_cm = pd.DataFrame(cm_i, index = [i for i in clss], columns = [i for i in clss])\n",
    "    plt.figure(figsize = (10, 7))\n",
    "\n",
    "    #plt.ylabel('True label')\n",
    "    #plt.xlabel('Pred label')\n",
    "    sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM\n",
    "import cv2\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![subtype](./sample/subtypes-of-hemorrhage.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME = [\"epidural\", \"intraparenchymal\", \"intraventricular\", \"subarachnoid\", \"subdural\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=50\n",
    "image_path = np.array([dataset_tst[N],])#[dataset_tst[:,1]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.splitext(os.path.basename(*image_path[:,0]))[0]\n",
    "check_label = [[CLASS_NAME[idx]] for idx, ans in enumerate(label_arr[N]) if ans == 1.]\n",
    "check_pred = [[CLASS_NAME[idx]] for idx, ans in enumerate(pred_arr[N]) if ans == 1.]\n",
    "check_output = [[output_arr[N][idx]] for idx, ans in enumerate(pred_arr[N]) if ans == 1.]\n",
    "print(f\"Ground truth: {check_label}\")\n",
    "print(f\"Prediction: {check_pred}\")\n",
    "print(f\"Confidence: {check_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = img_loader(*image_path[:,0])\n",
    "input_img = cv2.resize(input_img, (512, 512))\n",
    "input_img = np.float32(input_img) / 255\n",
    "rgb_img = np.array(Image.open(*image_path[:,0]).convert(\"RGB\"))\n",
    "rgb_img = cv2.resize(rgb_img, (512, 512))\n",
    "rgb_img = np.float32(rgb_img) / 255\n",
    "\n",
    "input_tensor = preprocess_image(input_img, mean=[0.5,], std=[0.5,])\n",
    "target_layer = net_pre.features.norm5\n",
    "cam = GradCAM(model=net_pre, target_layer=target_layer, use_cuda=True)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, target_category=2)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(rgb_img, cmap='gray')\n",
    "ax[0].set_title(f'original image: {fname}')\n",
    "ax[1].imshow(cam_image)\n",
    "ax[1].set_title('CAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=16\n",
    "image_path = np.array([dataset_tst[N],])#[dataset_tst[:,1]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.splitext(os.path.basename(*image_path[:,0]))[0]\n",
    "check_label = [[CLASS_NAME[idx]] for idx, ans in enumerate(label_arr[N]) if ans == 1.]\n",
    "check_pred = [[CLASS_NAME[idx]] for idx, ans in enumerate(pred_arr[N]) if ans == 1.]\n",
    "check_output = [[output_arr[N][idx]] for idx, ans in enumerate(pred_arr[N]) if ans == 1.]\n",
    "print(f\"Ground truth: {check_label}\")\n",
    "print(f\"Prediction: {check_pred}\")\n",
    "print(f\"Confidence: {check_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = img_loader(*image_path[:,0])\n",
    "input_img = cv2.resize(input_img, (512, 512))\n",
    "input_img = np.float32(input_img) / 255\n",
    "rgb_img = np.array(Image.open(*image_path[:,0]).convert(\"RGB\"))\n",
    "rgb_img = cv2.resize(rgb_img, (512, 512))\n",
    "rgb_img = np.float32(rgb_img) / 255\n",
    "\n",
    "input_tensor = preprocess_image(input_img, mean=[0.5,], std=[0.5,])\n",
    "target_layer = net_pre.features.norm5\n",
    "cam = GradCAM(model=net_pre, target_layer=target_layer, use_cuda=True)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, target_category=None)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(rgb_img, cmap='gray')\n",
    "ax[0].set_title(f'original image: {fname}')\n",
    "ax[1].imshow(cam_image)\n",
    "ax[1].set_title('CAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=316\n",
    "image_path = np.array([dataset_tst[N],])#[dataset_tst[:,1]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.splitext(os.path.basename(*image_path[:,0]))[0]\n",
    "check_label = [[CLASS_NAME[idx]] for idx, ans in enumerate(label_arr[N]) if ans == 1.]\n",
    "check_pred = [[CLASS_NAME[idx]] for idx, ans in enumerate(pred_arr[N]) if ans == 1.]\n",
    "check_output = [[output_arr[N][idx]] for idx, ans in enumerate(pred_arr[N]) if ans == 1.]\n",
    "print(f\"Ground truth: {check_label}\")\n",
    "print(f\"Prediction: {check_pred}\")\n",
    "print(f\"Confidence: {check_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = img_loader(*image_path[:,0])\n",
    "input_img = cv2.resize(input_img, (512, 512))\n",
    "input_img = np.float32(input_img) / 255\n",
    "rgb_img = np.array(Image.open(*image_path[:,0]).convert(\"RGB\"))\n",
    "rgb_img = cv2.resize(rgb_img, (512, 512))\n",
    "rgb_img = np.float32(rgb_img) / 255\n",
    "\n",
    "input_tensor = preprocess_image(input_img, mean=[0.5,], std=[0.5,])\n",
    "target_layer = net_pre.features.norm5\n",
    "cam = GradCAM(model=net_pre, target_layer=target_layer, use_cuda=True)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, target_category=None)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(rgb_img, cmap='gray')\n",
    "ax[0].set_title(f'original image: {fname}')\n",
    "ax[1].imshow(cam_image)\n",
    "ax[1].set_title('CAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=478\n",
    "image_path = np.array([dataset_tst[N],])#[dataset_tst[:,1]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.splitext(os.path.basename(*image_path[:,0]))[0]\n",
    "check_label = [[CLASS_NAME[idx]] for idx, ans in enumerate(label_arr[N]) if ans == 1.]\n",
    "check_pred = [[CLASS_NAME[idx]] for idx, ans in enumerate(pred_arr[N]) if ans == 1.]\n",
    "check_output = [[output_arr[N][idx]] for idx, ans in enumerate(pred_arr[N]) if ans == 1.]\n",
    "print(f\"Ground truth: {check_label}\")\n",
    "print(f\"Prediction: {check_pred}\")\n",
    "print(f\"Confidence: {check_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = img_loader(*image_path[:,0])\n",
    "input_img = cv2.resize(input_img, (512, 512))\n",
    "input_img = np.float32(input_img) / 255\n",
    "rgb_img = np.array(Image.open(*image_path[:,0]).convert(\"RGB\"))\n",
    "rgb_img = cv2.resize(rgb_img, (512, 512))\n",
    "rgb_img = np.float32(rgb_img) / 255\n",
    "\n",
    "input_tensor = preprocess_image(input_img, mean=[0.5,], std=[0.5,])\n",
    "target_layer = net_pre.features.norm5\n",
    "cam = GradCAM(model=net_pre, target_layer=target_layer, use_cuda=True)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, target_category=None)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(rgb_img, cmap='gray')\n",
    "ax[0].set_title(f'original image: {fname}')\n",
    "ax[1].imshow(cam_image)\n",
    "ax[1].set_title('CAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#False Positive and False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=405\n",
    "image_path = np.array([dataset_tst[N],])#[dataset_tst[:,1]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.splitext(os.path.basename(*image_path[:,0]))[0]\n",
    "check_label = [[CLASS_NAME[idx]] for idx, ans in enumerate(label_arr[N]) if ans == 1.]\n",
    "check_pred = [[CLASS_NAME[idx]] for idx, ans in enumerate(pred_arr[N]) if ans == 1.]\n",
    "check_output = [[output_arr[N][idx]] for idx, ans in enumerate(pred_arr[N]) if ans == 1.]\n",
    "print(f\"Ground truth: {check_label}\")\n",
    "print(f\"Prediction: {check_pred}\")\n",
    "print(f\"Confidence: {check_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = img_loader(*image_path[:,0])\n",
    "input_img = cv2.resize(input_img, (512, 512))\n",
    "input_img = np.float32(input_img) / 255\n",
    "rgb_img = np.array(Image.open(*image_path[:,0]).convert(\"RGB\"))\n",
    "rgb_img = cv2.resize(rgb_img, (512, 512))\n",
    "rgb_img = np.float32(rgb_img) / 255\n",
    "\n",
    "input_tensor = preprocess_image(input_img, mean=[0.5,], std=[0.5,])\n",
    "target_layer = net_pre.features.norm5\n",
    "cam = GradCAM(model=net_pre, target_layer=target_layer, use_cuda=True)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, target_category=None)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(rgb_img, cmap='gray')\n",
    "ax[0].set_title(f'original image: {fname}')\n",
    "ax[1].imshow(cam_image)\n",
    "ax[1].set_title('CAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
