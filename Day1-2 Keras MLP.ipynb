{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younggon2/Education-ComputerVision-DeepLearning/blob/master/Day1-2%20Keras%20MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gTEyq5ho80f"
      },
      "source": [
        "# Keras 실습\n",
        "* Tensorflow 2.x로 넘어오면서 Tensorflow와 Keras가 통합되어 가는 중\n",
        "* 실습에서 사용할 colab에서는 Tensorflow 2.3을 사용하기 때문에 tf.keras 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGwJ0Ao7pFx8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yao6RdxTiHC9"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHnMCg4biMcr"
      },
      "source": [
        "## STEP 1: Fashion MNIST 데이터 읽기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzoCyzywjg_I"
      },
      "source": [
        "![대체 텍스트](https://www.pyimagesearch.com/wp-content/uploads/2019/02/fashion_mnist_dataset_sample.png)\n",
        "![대체 텍스트](https://www.pyimagesearch.com/wp-content/uploads/2019/02/fashion_mnist_obtaining.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81jYUWW1iIpb"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
        "\n",
        "# initialize the label name\n",
        "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
        "              \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLAeSq7BihIA"
      },
      "source": [
        "## STEP 2: 데이터 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAdzSqvnifrL"
      },
      "source": [
        "plt_row = 5\n",
        "plt_col = 5\n",
        "\n",
        "width = height = 28\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
        "\n",
        "f, axarr = plt.subplots(plt_row, plt_col)\n",
        "\n",
        "for i in range(plt_row*plt_col):\n",
        "    sub_plt = axarr[int(i/plt_row), i%plt_col]\n",
        "    sub_plt.axis('off')\n",
        "    sub_plt.imshow(testX[i].reshape(width, height), cmap='gray')\n",
        "    sub_plt_title = 'R: ' + labelNames[testY[i]]\n",
        "    sub_plt.set_title(sub_plt_title)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECVr7Bfaixzg"
      },
      "source": [
        "## STEP 3: 딥러닝을 위한 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsloiL0Rizn5"
      },
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "width = height = 28\n",
        "num_pixels = width * height\n",
        "trainX = trainX.reshape(60000, num_pixels).astype('float32') / 255.0\n",
        "testX = testX.reshape(10000, num_pixels).astype('float32') / 255.0\n",
        "\n",
        "# 훈련셋과 검증셋 분리\n",
        "valX = trainX[50000:]\n",
        "valY = trainY[50000:]\n",
        "trainX = trainX[:50000]\n",
        "trainY = trainY[:50000]\n",
        "\n",
        "# one hot encode outputs\n",
        "num_classes = 10\n",
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes)\n",
        "valY = tf.keras.utils.to_categorical(valY, num_classes)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes)\n",
        "\n",
        "print ('train shape: \\t', trainX.shape)\n",
        "print ('valid shape: \\t', valX.shape)\n",
        "print ('test shape: \\t', testX.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN99O7EhjPQy"
      },
      "source": [
        "![대체 텍스트](https://www.simplilearn.com/ice9/free_resources_article_thumb/diagram-of-a-biological-neuron.jpg)\n",
        "![대체 텍스트](http://bit.ly/2ldH0Bg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cSC5Vr7i99q"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "def logistic_regression_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(num_classes, input_dim=num_pixels, kernel_initializer='normal', activation='softmax'))\n",
        "\n",
        "    # compile model\n",
        "    sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SOT25g1j1-V"
      },
      "source": [
        "## STEP 5: 첫 번째 인공지능 모델 학습!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL7emaIfj0og"
      },
      "source": [
        "model = logistic_regression_model()\n",
        "model.summary()\n",
        "# fix random seed for reproductibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# FIT THE MODEL - OPTIMIZATION\n",
        "hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=1)\n",
        "model.save('logistic_regression_model.h5')\n",
        "\n",
        "# 학습과정 살펴보기\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_ylim([0.0, 1.5])\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylim([0.5, 1.0])\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhB82iPxkKwC"
      },
      "source": [
        "## STEP 6: 결과 확인 (테스트 데이터셋)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwtIlHwHkA_r"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(testX, testY, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUntm72gkPvw"
      },
      "source": [
        "## STEP 7: 학습된 weight 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tylPAMiHkRr5"
      },
      "source": [
        "# Visualize weights\n",
        "W = model.layers[0].get_weights()[0]\n",
        "print(\"W shape : \", W.shape)\n",
        "\n",
        "W = np.transpose(W, (1,0))\n",
        "\n",
        "plt.figure(figsize=(15, 15), frameon=False)\n",
        "for ind, val in enumerate(W):\n",
        "    plt.subplot(5, 5, ind + 1)\n",
        "    im = val.reshape((28,28))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(im, cmap='gray',interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB_0VNlqkspG"
      },
      "source": [
        "## STEP 8: 두 번째 인공지능 모델 (Multi Layer Perceptron, MLP)\n",
        "![대체 텍스트](https://www.researchgate.net/profile/Hadley_Brooks/publication/270274130/figure/fig3/AS:667886670594050@1536247999230/Architecture-of-a-multilayer-neural-network-with-one-hidden-layer-The-input-layer.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xee71_UtkvYZ"
      },
      "source": [
        "def multi_layer_perceptron_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_dim=num_pixels, kernel_initializer='normal', activation='sigmoid'))\n",
        "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\n",
        "    # compile model\n",
        "    sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHu06vLhk-iT"
      },
      "source": [
        "# build the model\n",
        "model = multi_layer_perceptron_model()\n",
        "model.summary()\n",
        "\n",
        "# fix random seed for reproductibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Fit the model\n",
        "hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=1)\n",
        "model.save('multi_layer_perceptron_model.h5')\n",
        "\n",
        "# 5. 학습과정 살펴보기\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_ylim([0.0, 1.5])\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylim([0.5, 1.0])\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EU9-VEylMNH"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(testX, testY, verbose=0)\n",
        "print(\"Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyxxAp5IlWPn"
      },
      "source": [
        "## STEP 9: 세 번째 인공지능 모델 (DEEP-MLP)\n",
        "![대체 텍스트](https://i.stack.imgur.com/OH3gI.png)\n",
        "![대체 텍스트](https://www.saedsayad.com/images/ANN_Sigmoid.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT09dcehlVRJ"
      },
      "source": [
        "def deep_perceptron_initial_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_dim=num_pixels, kernel_initializer='normal', activation='sigmoid'))\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='sigmoid'))\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='sigmoid'))\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='sigmoid'))\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='sigmoid'))\n",
        "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\n",
        "    # compile model\n",
        "    sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSITHoHeluQ8"
      },
      "source": [
        "# build the model\n",
        "model = deep_perceptron_initial_model()\n",
        "model.summary()\n",
        "\n",
        "# fix random seed for reproductibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Fit the model\n",
        "hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=1)\n",
        "model.save('deep_perceptron_initial_model.h5')\n",
        "\n",
        "# 5. 학습과정 살펴보기\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF9aFJLClxpp"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(testX, testY, verbose=0)\n",
        "print(\"Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF_IxtU5l2Au"
      },
      "source": [
        "## STEP 10: 세 번째 인공지능 모델의 문제점 개선\n",
        "![대체 텍스트](https://image.slidesharecdn.com/usuconference-deeplearning-160418191119/95/introduction-to-deep-learning-7-638.jpg?cb=1461006739)\n",
        "![대체 텍스트](https://smartstuartkim.files.wordpress.com/2019/02/vanishinggradient-1.png?w=1140&h=492)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge-jeqx-l0Dq"
      },
      "source": [
        "#  Hint\n",
        "# 'relu'\n",
        "\n",
        "def deep_perceptron_model_with_relu():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_dim=num_pixels, kernel_initializer='normal', activation='????'))\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='????'))\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='????'))\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='????'))\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='????'))\n",
        "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "    # compile model\n",
        "\n",
        "    sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54gFwF4ZoH1H"
      },
      "source": [
        "# build the model\n",
        "model = deep_perceptron_model_with_relu()\n",
        "model.summary()\n",
        "\n",
        "# fix random seed for reproductibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Fit the model\n",
        "hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=1)\n",
        "model.save('deep_perceptron_model_with_dropout.h5')\n",
        "\n",
        "# 5. 학습과정 살펴보기\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_ylim([0.0, 1.5])\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylim([0.5, 1.0])\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8mN03MuoPtA"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(testX, testY, verbose=0)\n",
        "print(\"Perceptron model with relu error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-y1sLiBoUQn"
      },
      "source": [
        "![대체 텍스트](https://miro.medium.com/max/1200/1*iWQzxhVlvadk6VAJjsgXgg.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grYSGlSPoZes"
      },
      "source": [
        "#  Hint\n",
        "# 'Dropout'\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "def deep_perceptron_model_with_relu_dropout():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(????(0.2))\n",
        "\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(????(0.2))\n",
        "\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(????(0.2))\n",
        "\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(????(0.2))\n",
        "\n",
        "    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(????(0.2))\n",
        "\n",
        "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "\n",
        "    # compile model\n",
        "    sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rsfvRWmoddZ"
      },
      "source": [
        "# build the model\n",
        "model = deep_perceptron_model_with_relu_dropout()\n",
        "model.summary()\n",
        "\n",
        "# fix random seed for reproductibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Fit the model\n",
        "hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=1)\n",
        "model.save('deep_perceptron_model_with_dropout.h5')\n",
        "\n",
        "# 5. 학습과정 살펴보기\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "loss_ax.set_ylim([0.0, 1.5])\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "acc_ax.set_ylim([0.5, 1.0])\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5kvv4OepCxO"
      },
      "source": [
        "# Final evaluation of the models\n",
        "scores = model.evaluate(testX, testY, verbose=0)\n",
        "print(\"Perceptron model with relu and dropout error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
